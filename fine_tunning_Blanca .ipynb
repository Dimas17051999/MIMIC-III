{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6eab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Preprocessing\n",
    "from sklearn import utils\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Models\n",
    "#!pip install xgboost\n",
    "import xgboost\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold, KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "##plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_tree\n",
    "from sklearn import tree\n",
    "import matplotlib.pylab as pl\n",
    "#import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "xgb.set_config(verbosity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cedc9486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================  Fine-tuning  ==============================================================\n",
      "-----------GridSearchCV-----------------\n",
      "===================== Training again with best parameters =========================================\n",
      "auc_train:0.9975172646105049,  auc_val:0.5, auc_test: 0.5, sens_test 0.0, spec_test: 1.0, f1_test 0.0, acc_test 0.9099099099099099\n",
      "{'C': 1000.0, 'class_weight': 'balanced', 'l1_ratio': 0.5, 'penalty': 'elasticnet', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#----------- Hyperparameter\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=2, random_state=422) #for training\n",
    "#--------------------------\n",
    "\n",
    "def read_data(raw_clinical_note):\n",
    "    \"\"\" Read clinical data \"\"\"\n",
    "    data = pd.read_csv(raw_clinical_note, header=0,na_filter=True)\n",
    "    col = data.columns\n",
    "    x = data.drop('dead', axis = 1) #features\n",
    "    y = data.dead #label\n",
    "    feature_list = list(x.columns)\n",
    "    return x, y, feature_list\n",
    "\n",
    "def generating_metrics(model, model_ehr, x, y):\n",
    "    \"\"\"Function to generate metrics: auc_score, sensitivity, specificity, f1, accuracy\"\"\"\n",
    "    if model == \"LR\" or model ==\"RF\" or model ==\"ADA\" or model ==\"GBT\" or model ==\"XGBT\" or model ==\"LightGB\":\n",
    "        y_pred_proba = model_ehr.predict_proba(x)[:, 1]\n",
    "        y_pred = model_ehr.predict(x)\n",
    "        y_predicted = np.where(y_pred > 0.5, 1, 0) #Turn probability to 0-1 binary output\n",
    "        acc = accuracy_score(y,y_predicted)\n",
    "        tn, fp, fn, tp = confusion_matrix(y,y_predicted).ravel()\n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(y, y_pred_proba)\n",
    "    else:\n",
    "        y_pred = model_ehr.predict(x)\n",
    "        y_predicted = np.where(y_pred > 0.5, 1, 0) #Turn probability to 0-1 binary output\n",
    "        acc = accuracy_score(y,y_predicted)\n",
    "        tn, fp, fn, tp = confusion_matrix(y,y_predicted).ravel()\n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(y, y_predicted)\n",
    "####################################\n",
    "    sensitivity = tp / (tp+fn) #####\n",
    "    specificity = tn / (tn+fp) #####\n",
    "####################################\n",
    "    auc_score = auc(false_positive_rate, true_positive_rate)\n",
    "    f1 = f1_score(y, y_predicted)\n",
    "    return auc_score, sensitivity, specificity, f1, acc, false_positive_rate, true_positive_rate\n",
    "\n",
    "def saving_metrics(model_name, logs_file, num_features, auc_train\n",
    "                   ,auc_val, sens_val, spec_val, f1_val, acc_val\n",
    "                   ,auc_test, sens_test, spec_test, f1_test, acc_test,fpr, tpr):\n",
    "    \"\"\" Saving final metrics in csv file.\n",
    "    Metrics generated during training, validation, testing steps are saved\"\"\"\n",
    "    name = pd.DataFrame({'model_name':model_name}, index=[0])\n",
    "    num_features = pd.DataFrame({'num_features':num_features}, index=[0])\n",
    "    auc_train = pd.DataFrame({'auc_train':auc_train},index = [0])\n",
    "    auc_val = pd.DataFrame({'auc_val':auc_val},index = [0])\n",
    "    sens_val = pd.DataFrame({'sens_val':sens_val},index = [0])\n",
    "    spec_val = pd.DataFrame({'spec_val':spec_val},index = [0])\n",
    "    f1_val = pd.DataFrame({'f1_val':f1_val},index = [0])\n",
    "    acc_val = pd.DataFrame({'acc_val':acc_val},index = [0])\n",
    "    auc_test = pd.DataFrame({'auc_test':auc_test},index = [0])\n",
    "    sens_test = pd.DataFrame({'sens_test':sens_test},index = [0])\n",
    "    spec_test = pd.DataFrame({'spec_test':spec_test},index = [0])\n",
    "    f1_test = pd.DataFrame({'f1_test':f1_test},index = [0])\n",
    "    acc_test = pd.DataFrame({'acc_test':acc_test},index = [0])\n",
    "\n",
    "    fpr = str(fpr)\n",
    "    tpr = str(tpr)\n",
    "    fpr = pd.DataFrame({'false_positive_rate':fpr},index = [0])\n",
    "    tpr = pd.DataFrame({'true_positive_rate':tpr},index = [0])\n",
    "\n",
    "    frames = [name, num_features, auc_train, auc_val,sens_val,spec_val,f1_val,acc_val,\n",
    "              auc_test,sens_test,spec_test,f1_test,acc_test, fpr, tpr]\n",
    "    resultado = pd.concat(frames, axis = 1)\n",
    "    url_log = model_name +'_metrics.csv'\n",
    "    url_log = os.path.join(logs_file,str(url_log))\n",
    "    resultado.to_csv(url_log)\n",
    "\n",
    "def create_folder(logs_file):\n",
    "    try:\n",
    "        if not os.path.exists(logs_file):\n",
    "            os.makedirs(logs_file)\n",
    "    except Exception as e:\n",
    "        raise\n",
    "\n",
    "def saving_parameters(num_features, best_params, auc_training, auc_validation, model_name,logs_file):\n",
    "    \"\"\" Once that fine-tuning was done, the best parameters are saved\"\"\"\n",
    "    name = pd.DataFrame({'model_name':model_name}, index=[0])\n",
    "    num_features = pd.DataFrame({'num_features':num_features}, index=[0])\n",
    "    auc_training = pd.DataFrame({'auc_training': auc_training}, index = [0])\n",
    "    auc_validation = pd.DataFrame({'auc_validation': auc_validation}, index = [0])\n",
    "    best_params = pd.DataFrame({'best_params': best_params})\n",
    "    frames = [name, auc_training, auc_validation, best_params]\n",
    "    resultado = pd.concat(frames, axis = 1)\n",
    "    output_file = model_name +'_parameters.csv'\n",
    "    output_file = os.path.join(logs_file,str(output_file))\n",
    "    resultado.to_csv(output_file)\n",
    "\n",
    "def imputer(set):\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    set = imputer.fit_transform(set)\n",
    "    return set\n",
    "\n",
    "def scaler(set):\n",
    "    scaler = StandardScaler()\n",
    "    set = scaler.fit_transform(set)\n",
    "    return set\n",
    "\n",
    "def features_selection(x_train, y_train,x_val,x_test,model,feature_list):\n",
    "    \"\"\"Feature ranking with recursive feature elimination using pipeline\"\"\"\n",
    "    n_features = x_train.shape[1]\n",
    "    print(\"n_features original: \",n_features)\n",
    "    if model == 'LR':\n",
    "        estimator = LogisticRegression(random_state = 442, penalty = 'elasticnet', solver= 'saga',l1_ratio=0.5)\n",
    "    if model == 'SVM':\n",
    "        estimator = svm.LinearSVC(class_weight = 'balanced', random_state = 442)\n",
    "    if model == 'SGD':\n",
    "        estimator = SGDClassifier(class_weight = 'balanced', random_state = 442)\n",
    "    if model == 'ADA':\n",
    "        estimator = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5, class_weight = 'balanced'),random_state = 442)\n",
    "    if model == 'RF':\n",
    "        estimator = RandomForestClassifier(random_state=442, class_weight = 'balanced')\n",
    "    if model == 'GBT':\n",
    "        estimator = GradientBoostingClassifier(random_state = 442)\n",
    "    if model == 'XGBT':\n",
    "        ratio = float(np.sum(y_train == 0)) / np.sum(y_train==1)\n",
    "        estimator = XGBClassifier(seed = 442,eval_metric = 'auc', scale_pos_weight = ratio)\n",
    "    if model == 'LightGB':\n",
    "        ratio = float(np.sum(y_train == 0)) / np.sum(y_train==1)\n",
    "        estimator = lgb.LGBMClassifier(seed = 442, scale_pos_weight = ratio)\n",
    "\n",
    "    print(\"Searching RFE\")\n",
    "    classifier = RFE(estimator=estimator, step=1)\n",
    "    model = Pipeline([('classifier', classifier)])\n",
    "    parameters = {'classifier__n_features_to_select': [int(n_features*0.25),int(n_features*0.5),int(n_features*0.75),n_features]}\n",
    "    grid = GridSearchCV(model, parameters, cv=3)\n",
    "    grid.fit(x_train, y_train)\n",
    "    num_features = grid.best_params_\n",
    "    num_features = re.sub(r'[^\\d]','',str(num_features))\n",
    "    print(\"Optimal number of features\",num_features)\n",
    "\n",
    "    print(\"SelectKBest\")\n",
    "    selector = SelectKBest(f_classif, k=int(num_features)) #we pass the \"optimal number of features\" discovered in the previous pass\n",
    "    selector.fit(x_train, y_train)\n",
    "    x_train = selector.transform(x_train).astype('float32')\n",
    "    x_val = selector.transform(x_val).astype('float32')\n",
    "    x_test = selector.transform(x_test).astype('float32')\n",
    "    feature_list = [feature_list[i] for i in selector.get_support(indices=True)]\n",
    "    return x_train, x_val, x_test,feature_list, num_features\n",
    "\n",
    "def mortality_model(train, model):\n",
    "    \"\"\"===================== Loading data ================================================================\"\"\"\n",
    "    #create_folder(logs_file)\n",
    "    x_train, y_train, feature_list = read_data(train)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.33, random_state=42)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.33, random_state=42)\n",
    "    #create_folder(logs_file)\n",
    "    x_train = scaler(x_train)\n",
    "    #x_val = scaler(x_val)\n",
    "    #x_test = scaler(x_test)\n",
    "    \n",
    "    \"\"\" Imbalanced classes \"\"\"\n",
    "    sample_weights = class_weight.compute_sample_weight('balanced', y_train)\n",
    "    print(\"=====================  Fine-tuning  ==============================================================\")\n",
    "    if model == 'LR':\n",
    "        x_train = (x_train-x_train.mean())/(x_train.max()-x_train.min()) #sd \n",
    "        parameters={\"C\":np.logspace(-3,3,7), \"penalty\":[\"elasticnet\"],\"solver\":['saga'], \"l1_ratio\":[0.5],\n",
    "                    \"class_weight\": ['balanced'],}\n",
    "        estimator = LogisticRegression()\n",
    "    if model == 'XGBT':\n",
    "        ratio = float(np.sum(y_train == 0)) / np.sum(y_train==1)\n",
    "        parameters={\"n_estimators\":[100,120], \"learning_rate\": [0.1,0.05],\"colsample_bytree\" : [0.4, 0.8],\n",
    "                    \"subsample\" : [0.8, 0.4], \"reg_alpha\" : [0.5], \"reg_lambda\": [2],\n",
    "                    \"objective\": ['binary:logistic'], \"max_depth\":[4, 2], \"gamma\":[10],\"rate_drop\": [0.5, 0.3],\n",
    "                    \"seed\": [422], \"eval_metric\": ['auc'],\n",
    "                    \"scale_pos_weight\": [ratio]}\n",
    "        estimator = xgb.XGBClassifier()\n",
    "    if model == 'SVM':\n",
    "        parameters={\"C\":np.logspace(-3,3,7), \"class_weight\": ['balanced'],\"random_state\": [422]}\n",
    "        estimator = svm.LinearSVC()\n",
    "    if model == 'RF':\n",
    "        parameters={\"n_estimators\":[100,200, 50,10], \"max_features\": ['log2'],\n",
    "                \"max_depth\" : [2, 4,6],\"criterion\":['gini'], \"min_impurity_decrease\":[1e-4, 1e-7],\n",
    "                \"class_weight\":['balanced'],\"random_state\": [422]}\n",
    "        estimator = RandomForestClassifier()\n",
    "    if model == 'ADA':\n",
    "        parameters={\"n_estimators\":[50, 100], \"learning_rate\": [1e-4, 1e-7],\"random_state\": [422]}\n",
    "        estimator = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5, class_weight = 'balanced'))\n",
    "    print(\"-----------GridSearchCV-----------------\")\n",
    "    grid = GridSearchCV(estimator=estimator, param_grid=parameters, cv = cv, scoring='roc_auc', refit = True)\n",
    "    grid.fit(x_train,y_train,sample_weight = sample_weights)\n",
    "    auc_train = grid.best_score_\n",
    "    best_params = grid.best_params_\n",
    "\n",
    "    print(\"===================== Training again with best parameters =========================================\")\n",
    "    if model == \"LR\":\n",
    "        model_ehr = LogisticRegression(**best_params)\n",
    "        model_ehr = model_ehr.fit(x_train,y_train)\n",
    "    if model == \"XGBT\":\n",
    "        model_ehr = xgb.XGBClassifier(**best_params)\n",
    "        model_ehr = model_ehr.fit(x_train,y_train)\n",
    "    if model == \"SVM\":\n",
    "        model_ehr = svm.LinearSVC(**best_params)\n",
    "        model_ehr = model_ehr.fit(x_train,y_train)\n",
    "    if model == \"RF\":\n",
    "        model_ehr = RandomForestClassifier(**best_params)\n",
    "        model_ehr = model_ehr.fit(x_train,y_train)\n",
    "    if model == \"ADA\":\n",
    "        model_ehr = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5, class_weight = 'balanced'),**best_params)\n",
    "        model_ehr = model_ehr.fit(x_train,y_train)    \n",
    "    \"\"\" Saving metrics\"\"\"\n",
    "    auc_val, sens_val, spec_val, f1_val, acc_val,_,_ = generating_metrics(model, model_ehr, x_val, y_val) #val_set\n",
    "    auc_test, sens_test, spec_test, f1_test, acc_test,fpr, tpr = generating_metrics(model, model_ehr, x_test, y_test) #test_set\n",
    "    print(\"auc_train:{},  auc_val:{}, auc_test: {}, sens_test {}, spec_test: {}, f1_test {}, acc_test {}\".format(auc_train,\n",
    "                                                                                                    auc_val, auc_test, sens_test, spec_test, f1_test, acc_test))\n",
    "    print(best_params)\n",
    "    #>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "mortality_model('dead_due_to_AHE_constant.csv' , SVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8b3fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
